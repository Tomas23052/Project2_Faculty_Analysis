#!/usr/bin/env python3
"""
IPT Faculty Performance Assessment - Advanced Dashboard
========================================================
Dashboard Streamlit avan√ßado com m√∫ltiplas funcionalidades:
- Interface multi-p√°gina
- Filtros din√¢micos
- Visualiza√ß√µes interativas
- Relat√≥rios export√°veis
- Sistema de alertas
- Benchmarking em tempo real
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
from datetime import datetime, timedelta
from pathlib import Path
import base64
from io import BytesIO
import zipfile
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="IPT Faculty Analytics",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Configura√ß√£o de estilo customizado
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 0.5rem 0;
    }
    .alert-critical {
        background-color: #ff4444;
        color: white;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.25rem 0;
    }
    .alert-warning {
        background-color: #ffaa00;
        color: white;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.25rem 0;
    }
    .alert-info {
        background-color: #0088cc;
        color: white;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.25rem 0;
    }
    .sidebar .sidebar-content {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    .stProgress .st-bo {
        background-color: #00cc88;
    }
</style>
""", unsafe_allow_html=True)

class AdvancedDashboard:
    """Dashboard avan√ßado para an√°lise de performance de docentes"""
    
    def __init__(self):
        self.data_dir = Path("data")
        self.load_data()
        
    def load_data(self):
        """Carregar todos os dados dispon√≠veis"""
        try:
            # Dados principais - try multiple files in order of preference
            main_data_files = [
                "faculty_research_metrics.csv",
                "faculty_enhanced_complete.csv", 
                "faculty_advanced_parsed.csv",
                "faculty_basic.csv",
                "faculty_enriched.csv"
            ]
            
            self.df_main = pd.DataFrame()
            for file in main_data_files:
                if (self.data_dir / file).exists():
                    self.df_main = pd.read_csv(self.data_dir / file)
                    st.info(f"‚úÖ Dados carregados de: {file}")
                    break
            
            if self.df_main.empty:
                st.warning("‚ö†Ô∏è Nenhum arquivo de dados principal encontrado")
            
            # Dados de clustering
            if (self.data_dir / "faculty_clusters.csv").exists():
                self.df_clusters = pd.read_csv(self.data_dir / "faculty_clusters.csv")
            else:
                self.df_clusters = pd.DataFrame()
            
            # M√©tricas de rede
            if (self.data_dir / "faculty_network_metrics.csv").exists():
                self.df_network = pd.read_csv(self.data_dir / "faculty_network_metrics.csv")
            else:
                self.df_network = pd.DataFrame()
            
            # Dados Scopus
            if (self.data_dir / "faculty_scopus_metrics.csv").exists():
                self.df_scopus = pd.read_csv(self.data_dir / "faculty_scopus_metrics.csv")
            else:
                self.df_scopus = pd.DataFrame()
            
            # Alertas
            if (self.data_dir / "faculty_alerts.csv").exists():
                self.df_alerts = pd.read_csv(self.data_dir / "faculty_alerts.csv")
            else:
                self.df_alerts = pd.DataFrame()
            
            # M√©tricas de monitoriza√ß√£o
            if (self.data_dir / "monitoring_metrics.json").exists():
                with open(self.data_dir / "monitoring_metrics.json", 'r') as f:
                    self.monitoring_data = json.load(f)
            else:
                self.monitoring_data = {}
            
            # An√°lise de benchmarking
            if (self.data_dir / "benchmark_analysis.json").exists():
                with open(self.data_dir / "benchmark_analysis.json", 'r') as f:
                    self.benchmark_data = json.load(f)
            else:
                self.benchmark_data = {}
            
            # Merge dos dados se dispon√≠vel
            if not self.df_main.empty:
                if not self.df_clusters.empty and 'name' in self.df_clusters.columns:
                    self.df_main = self.df_main.merge(self.df_clusters, on='name', how='left', suffixes=('', '_cluster'))
                
                if not self.df_network.empty and 'name' in self.df_network.columns:
                    self.df_main = self.df_main.merge(self.df_network, on='name', how='left', suffixes=('', '_network'))
                
                if not self.df_scopus.empty and 'name' in self.df_scopus.columns:
                    self.df_main = self.df_main.merge(self.df_scopus, on='name', how='left', suffixes=('', '_scopus'))
            
            # Log data summary
            st.sidebar.info(f"üìä **Resumo dos Dados:**\n\n"
                          f"‚Ä¢ Principal: {len(self.df_main)} registros\n"
                          f"‚Ä¢ Clusters: {len(self.df_clusters)} registros\n"
                          f"‚Ä¢ Rede: {len(self.df_network)} registros\n"
                          f"‚Ä¢ Scopus: {len(self.df_scopus)} registros\n"
                          f"‚Ä¢ Alertas: {len(self.df_alerts)} registros")
            
        except Exception as e:
            st.error(f"Erro ao carregar dados: {e}")
            # Create empty dataframes as fallback
            self.df_main = pd.DataFrame()
            self.df_clusters = pd.DataFrame()
            self.df_network = pd.DataFrame()
            self.df_scopus = pd.DataFrame()
            self.df_alerts = pd.DataFrame()
            self.monitoring_data = {}
            self.benchmark_data = {}
    
    @property
    def df(self):
        """Alias for main dataframe for backward compatibility"""
        return self.df_main
    
    def create_sidebar_filters(self):
        """Criar filtros na sidebar"""
        st.sidebar.header("üéõÔ∏è Filtros e Configura√ß√µes")
        
        filters = {}
        
        if not self.df_main.empty:
            # Filtro por categoria
            if 'category' in self.df_main.columns:
                categories = ['Todos'] + list(self.df_main['category'].dropna().unique())
                filters['category'] = st.sidebar.selectbox(
                    "Categoria Acad√©mica",
                    categories,
                    index=0
                )
            
            # Filtro por cluster
            if 'Cluster' in self.df_main.columns:
                clusters = ['Todos'] + [f"Cluster {i}" for i in sorted(self.df_main['Cluster'].dropna().unique())]
                filters['cluster'] = st.sidebar.selectbox(
                    "Cluster de Performance",
                    clusters,
                    index=0
                )
            
            # Filtro por produtividade
            if 'orcid_works_count' in self.df_main.columns:
                pub_range = st.sidebar.slider(
                    "N√∫mero de Publica√ß√µes",
                    min_value=0,
                    max_value=int(self.df_main['orcid_works_count'].max()) if not self.df_main['orcid_works_count'].isna().all() else 100,
                    value=(0, int(self.df_main['orcid_works_count'].max()) if not self.df_main['orcid_works_count'].isna().all() else 100),
                    step=5
                )
                filters['publications'] = pub_range
            
            # Filtro por cita√ß√µes (se dispon√≠vel)
            if 'scopus_citations' in self.df_main.columns:
                citations_range = st.sidebar.slider(
                    "N√∫mero de Cita√ß√µes",
                    min_value=0,
                    max_value=int(self.df_main['scopus_citations'].max()) if not self.df_main['scopus_citations'].isna().all() else 1000,
                    value=(0, int(self.df_main['scopus_citations'].max()) if not self.df_main['scopus_citations'].isna().all() else 1000),
                    step=10
                )
                filters['citations'] = citations_range
        
        # Configura√ß√µes de visualiza√ß√£o
        st.sidebar.subheader("üìä Configura√ß√µes de Visualiza√ß√£o")
        filters['show_confidence'] = st.sidebar.checkbox("Mostrar intervalos de confian√ßa", False)
        filters['show_trends'] = st.sidebar.checkbox("Mostrar linhas de tend√™ncia", True)
        filters['color_scheme'] = st.sidebar.selectbox(
            "Esquema de Cores",
            ["Viridis", "Plasma", "Blues", "Reds", "Greens"],
            index=0
        )
        
        return filters
    
    def apply_filters(self, df, filters):
        """Aplicar filtros aos dados"""
        if df.empty:
            return df
        
        filtered_df = df.copy()
        
        # Filtro por categoria
        if filters.get('category') and filters['category'] != 'Todos':
            filtered_df = filtered_df[filtered_df['category'] == filters['category']]
        
        # Filtro por cluster
        if filters.get('cluster') and filters['cluster'] != 'Todos':
            cluster_num = int(filters['cluster'].split()[-1])
            filtered_df = filtered_df[filtered_df['Cluster'] == cluster_num]
        
        # Filtro por publica√ß√µes
        if filters.get('publications'):
            min_pub, max_pub = filters['publications']
            if 'orcid_works_count' in filtered_df.columns:
                filtered_df = filtered_df[
                    (filtered_df['orcid_works_count'] >= min_pub) & 
                    (filtered_df['orcid_works_count'] <= max_pub)
                ]
        
        # Filtro por cita√ß√µes
        if filters.get('citations'):
            min_cit, max_cit = filters['citations']
            if 'scopus_citations' in filtered_df.columns:
                filtered_df = filtered_df[
                    (filtered_df['scopus_citations'] >= min_cit) & 
                    (filtered_df['scopus_citations'] <= max_cit)
                ]
        
        return filtered_df
    
    def show_overview_page(self, filters):
        """P√°gina de vis√£o geral"""
        st.markdown('<h1 class="main-header">üéì IPT Faculty Analytics Dashboard</h1>', unsafe_allow_html=True)
        
        if self.df_main.empty:
            st.warning("‚ö†Ô∏è Nenhum dado carregado. Execute o pipeline de coleta primeiro.")
            return
        
        filtered_df = self.apply_filters(self.df_main, filters)
        
        # M√©tricas principais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_faculty = len(filtered_df)
            st.metric("üë• Total de Docentes", total_faculty)
        
        with col2:
            if 'orcid_works_count' in filtered_df.columns:
                avg_publications = filtered_df['orcid_works_count'].mean()
                st.metric("üìö Publica√ß√µes M√©dias", f"{avg_publications:.1f}")
            else:
                st.metric("üìö Publica√ß√µes M√©dias", "N/A")
        
        with col3:
            if 'scopus_citations' in filtered_df.columns:
                avg_citations = filtered_df['scopus_citations'].mean()
                st.metric("üìà Cita√ß√µes M√©dias", f"{avg_citations:.0f}")
            else:
                st.metric("üìà Cita√ß√µes M√©dias", "N/A")
        
        with col4:
            # Calcular score de performance
            performance_score = self.calculate_performance_score(filtered_df)
            st.metric("‚≠ê Performance Score", f"{performance_score:.1f}/100")
        
        # Gr√°ficos principais
        col1, col2 = st.columns(2)
        
        with col1:
            self.show_category_distribution(filtered_df, filters)
        
        with col2:
            self.show_performance_scatter(filtered_df, filters)
        
        # Alertas
        self.show_alerts_summary()
        
        # Tend√™ncias temporais
        st.subheader("üìà Tend√™ncias e Proje√ß√µes")
        self.show_trends_projection(filtered_df)
    
    def show_performance_analysis(self, filters):
        """P√°gina de an√°lise de performance"""
        st.header("üìä An√°lise Detalhada de Performance")
        
        if self.df_main.empty:
            st.warning("‚ö†Ô∏è Nenhum dado dispon√≠vel para an√°lise.")
            return
        
        filtered_df = self.apply_filters(self.df_main, filters)
        
        # An√°lise de clusters
        if 'Cluster' in filtered_df.columns:
            st.subheader("üéØ An√°lise de Clusters")
            self.show_cluster_analysis(filtered_df, filters)
        
        # An√°lise de rede
        if not self.df_network.empty:
            st.subheader("üåê An√°lise de Rede de Colabora√ß√£o")
            self.show_network_analysis()
        
        # Top performers
        st.subheader("üèÜ Top Performers")
        self.show_top_performers(filtered_df)
        
        # Performance por departamento
        if 'department' in filtered_df.columns:
            st.subheader("üè¢ Performance por Departamento")
            self.show_department_performance(filtered_df, filters)
    
    def show_benchmarking_page(self, filters):
        """P√°gina de benchmarking"""
        st.header("üèÜ Benchmarking Internacional")
        
        if not self.benchmark_data:
            st.warning("‚ö†Ô∏è Dados de benchmarking n√£o dispon√≠veis.")
            return
        
        # Compara√ß√£o com benchmarks
        self.show_benchmark_comparison()
        
        # Gap analysis
        st.subheader("üìä An√°lise de Gaps")
        self.show_gap_analysis()
        
        # Roadmap
        st.subheader("üõ£Ô∏è Roadmap Estrat√©gico")
        self.show_strategic_roadmap()
    
    def show_reports_page(self, filters):
        """P√°gina de relat√≥rios"""
        st.header("üìã Relat√≥rios e Exporta√ß√£o")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìä Relat√≥rios Dispon√≠veis")
            
            if st.button("üìà Relat√≥rio Executivo"):
                self.generate_executive_report()
            
            if st.button("üìã Relat√≥rio de Compliance"):
                self.generate_compliance_report()
            
            if st.button("üîç Relat√≥rio Detalhado"):
                self.generate_detailed_report()
        
        with col2:
            st.subheader("üíæ Exportar Dados")
            
            if st.button("üìä Exportar para Excel"):
                self.export_to_excel()
            
            if st.button("üìÑ Exportar para PDF"):
                self.export_to_pdf()
            
            if st.button("üì¶ Exportar Tudo (ZIP)"):
                self.export_all_data()
    
    def calculate_performance_score(self, df):
        """Calcular score de performance composto"""
        if df.empty:
            return 0
        
        scores = []
        
        # Publica√ß√µes (40%)
        if 'orcid_works_count' in df.columns:
            pub_score = df['orcid_works_count'].fillna(0).mean() / 50 * 40
            scores.append(min(pub_score, 40))
        
        # Cita√ß√µes (30%)
        if 'scopus_citations' in df.columns:
            cit_score = df['scopus_citations'].fillna(0).mean() / 500 * 30
            scores.append(min(cit_score, 30))
        
        # Colabora√ß√£o (20%)
        if 'degree_centrality' in df.columns:
            collab_score = df['degree_centrality'].fillna(0).mean() * 20
            scores.append(min(collab_score, 20))
        
        # Qualidade (10%)
        if 'q1_publications' in df.columns and 'scopus_publications' in df.columns:
            q1_ratio = df['q1_publications'].fillna(0).sum() / max(df['scopus_publications'].fillna(0).sum(), 1)
            quality_score = q1_ratio * 10
            scores.append(min(quality_score, 10))
        
        return sum(scores) if scores else 0
    
    def show_category_distribution(self, df, filters):
        """Mostrar distribui√ß√£o por categoria"""
        if 'category' not in df.columns:
            st.info("Dados de categoria n√£o dispon√≠veis")
            return
        
        st.subheader("üë®‚Äçüè´ Distribui√ß√£o por Categoria")
        
        category_counts = df['category'].value_counts()
        
        fig = px.pie(
            values=category_counts.values,
            names=category_counts.index,
            title="Distribui√ß√£o de Docentes por Categoria",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        
        fig.update_traces(textposition='inside', textinfo='percent+label')
        fig.update_layout(height=400)
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_performance_scatter(self, df, filters):
        """Mostrar scatter plot de performance"""
        if 'orcid_works_count' not in df.columns:
            st.info("Dados de publica√ß√µes n√£o dispon√≠veis")
            return
        
        st.subheader("üìä Performance: Publica√ß√µes vs Cita√ß√µes")
        
        x_col = 'orcid_works_count'
        y_col = 'scopus_citations' if 'scopus_citations' in df.columns else 'orcid_recent_works'
        
        fig = px.scatter(
            df,
            x=x_col,
            y=y_col,
            color='category' if 'category' in df.columns else None,
            size='orcid_funding_count' if 'orcid_funding_count' in df.columns else None,
            hover_name='name',
            title="Rela√ß√£o entre Publica√ß√µes e Impacto",
            color_discrete_sequence=px.colors.qualitative.Set2
        )
        
        if filters.get('show_trends'):
            fig.add_traces(px.scatter(df, x=x_col, y=y_col, trendline="ols").data[1:])
        
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    def show_alerts_summary(self):
        """Mostrar resumo de alertas"""
        if self.df_alerts.empty:
            return
        
        st.subheader("üö® Alertas Ativos")
        
        col1, col2, col3 = st.columns(3)
        
        critical_alerts = len(self.df_alerts[self.df_alerts['priority'] == 'ALTA'])
        warning_alerts = len(self.df_alerts[self.df_alerts['priority'] == 'M√âDIA'])
        info_alerts = len(self.df_alerts[self.df_alerts['priority'] == 'BAIXA'])
        
        with col1:
            st.metric("üî¥ Cr√≠ticos", critical_alerts)
        
        with col2:
            st.metric("üü° Avisos", warning_alerts)
        
        with col3:
            st.metric("üîµ Informativos", info_alerts)
        
        # Mostrar alertas mais importantes
        if critical_alerts > 0:
            st.error("‚ö†Ô∏è Alertas Cr√≠ticos Encontrados!")
            critical = self.df_alerts[self.df_alerts['priority'] == 'ALTA']
            for _, alert in critical.head(3).iterrows():
                st.markdown(f"**{alert['category']}**: {alert['message']}")
    
    def show_trends_projection(self, df):
        """Mostrar tend√™ncias e proje√ß√µes"""
        # Simular dados hist√≥ricos para demonstra√ß√£o
        years = list(range(2020, 2025))
        
        if 'orcid_works_count' in df.columns:
            current_avg = df['orcid_works_count'].mean()
        else:
            current_avg = 30
        
        # Simular tend√™ncia hist√≥rica
        historical_data = [current_avg * (1 - 0.1 * (2024 - year)) for year in years]
        
        # Proje√ß√£o futura
        future_years = list(range(2025, 2028))
        projections = [current_avg * (1 + 0.08 * (year - 2024)) for year in future_years]
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=years,
            y=historical_data,
            mode='lines+markers',
            name='Dados Hist√≥ricos',
            line=dict(color='blue')
        ))
        
        fig.add_trace(go.Scatter(
            x=future_years,
            y=projections,
            mode='lines+markers',
            name='Proje√ß√£o',
            line=dict(color='red', dash='dash')
        ))
        
        fig.update_layout(
            title="Evolu√ß√£o da Produ√ß√£o Cient√≠fica",
            xaxis_title="Ano",
            yaxis_title="Publica√ß√µes M√©dias",
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_cluster_analysis(self, df, filters):
        """Mostrar an√°lise de clusters"""
        cluster_summary = df.groupby('Cluster').agg({
            'name': 'count',
            'orcid_works_count': 'mean',
            'orcid_recent_works': 'mean' if 'orcid_recent_works' in df.columns else lambda x: 0
        }).round(2)
        
        cluster_summary.columns = ['N√∫mero de Docentes', 'Publica√ß√µes M√©dias', 'Publica√ß√µes Recentes']
        
        st.dataframe(cluster_summary, use_container_width=True)
        
        # Visualiza√ß√£o dos clusters
        if 'orcid_works_count' in df.columns and 'orcid_recent_works' in df.columns:
            fig = px.scatter(
                df,
                x='orcid_works_count',
                y='orcid_recent_works',
                color='Cluster',
                title="Clusters de Performance",
                labels={'orcid_works_count': 'Total de Publica√ß√µes', 'orcid_recent_works': 'Publica√ß√µes Recentes'}
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    def show_network_analysis(self):
        """Mostrar an√°lise de rede"""
        if self.df_network.empty:
            st.info("Dados de rede n√£o dispon√≠veis")
            return
        
        # Top colaboradores
        top_collaborators = self.df_network.nlargest(10, 'degree_centrality')
        
        fig = px.bar(
            top_collaborators,
            x='degree_centrality',
            y='name',
            orientation='h',
            title="Top 10 Colaboradores (Centralidade de Grau)"
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_top_performers(self, df):
        """Mostrar top performers"""
        if 'orcid_works_count' not in df.columns:
            st.info("Dados de performance n√£o dispon√≠veis")
            return
        
        # Calcular score para cada docente
        df_performance = df.copy()
        
        # Score baseado em m√∫ltiplas m√©tricas
        scores = []
        for _, row in df_performance.iterrows():
            score = 0
            
            # Publica√ß√µes (40%)
            pubs = row.get('orcid_works_count', 0)
            score += min(pubs / 100, 1) * 40
            
            # Cita√ß√µes (30%)
            if 'scopus_citations' in row:
                citations = row.get('scopus_citations', 0)
                score += min(citations / 1000, 1) * 30
            
            # Publica√ß√µes recentes (20%)
            recent = row.get('orcid_recent_works', 0)
            score += min(recent / 20, 1) * 20
            
            # H-index (10%)
            if 'scopus_h_index' in row:
                h_index = row.get('scopus_h_index', 0)
                score += min(h_index / 20, 1) * 10
            
            scores.append(score)
        
        df_performance['performance_score'] = scores
        
        # Top 10
        top_performers = df_performance.nlargest(10, 'performance_score')
        
        fig = px.bar(
            top_performers,
            x='performance_score',
            y='name',
            orientation='h',
            title="Top 10 Performers (Score Composto)",
            color='performance_score',
            color_continuous_scale='Viridis'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_department_performance(self, df, filters):
        """Mostrar performance por departamento"""
        if 'department' not in df.columns or df['department'].isna().all():
            st.info("Dados de departamento n√£o dispon√≠veis")
            return
        
        dept_performance = df.groupby('department').agg({
            'orcid_works_count': ['count', 'mean', 'sum'],
            'orcid_recent_works': 'mean' if 'orcid_recent_works' in df.columns else lambda x: 0
        }).round(2)
        
        st.dataframe(dept_performance, use_container_width=True)
    
    def show_benchmark_comparison(self):
        """Mostrar compara√ß√£o com benchmarks"""
        if 'benchmark_comparison' not in self.benchmark_data:
            st.info("Dados de benchmark n√£o dispon√≠veis")
            return
        
        benchmark_df = pd.DataFrame(self.benchmark_data['benchmark_comparison'])
        
        st.dataframe(benchmark_df.T, use_container_width=True)
        
        # Gr√°fico de compara√ß√£o
        # M√©tricas dispon√≠veis
        available_metrics = []
        
        if 'orcid_works_count' in self.df_main.columns:
            available_metrics.append('orcid_works_count')
        if 'orcid_recent_works' in self.df_main.columns:
            available_metrics.append('orcid_recent_works')
        if 'orcid_funding_count' in self.df_main.columns:
            available_metrics.append('orcid_funding_count')
        
        if not available_metrics:
            st.warning("Nenhuma m√©trica de pesquisa dispon√≠vel para compara√ß√£o.")
            return
        
        metrics = available_metrics
        
        fig = go.Figure()
        
        for metric in metrics:
            if metric in benchmark_df.columns:
                fig.add_trace(go.Bar(
                    name=metric,
                    x=benchmark_df.index,
                    y=benchmark_df.loc[metric]
                ))
        
        fig.update_layout(
            title="Compara√ß√£o com Benchmarks",
            xaxis_title="Institui√ß√µes",
            yaxis_title="Valores",
            barmode='group'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_gap_analysis(self):
        """Mostrar an√°lise de gaps"""
        if 'gaps' not in self.benchmark_data:
            st.info("An√°lise de gaps n√£o dispon√≠vel")
            return
        
        gaps_data = self.benchmark_data['gaps']
        
        metrics = list(gaps_data.keys())
        gap_percentages = [gaps_data[metric]['percentage'] for metric in metrics]
        
        fig = px.bar(
            x=metrics,
            y=gap_percentages,
            title="Gaps vs Benchmarks (%)",
            color=gap_percentages,
            color_continuous_scale='Reds'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_strategic_roadmap(self):
        """Mostrar roadmap estrat√©gico"""
        if 'roadmap' not in self.benchmark_data:
            st.info("Roadmap n√£o dispon√≠vel")
            return
        
        roadmap = self.benchmark_data['roadmap']
        
        for year, plan in roadmap.items():
            with st.expander(f"üìÖ {year} - {plan['foco']}"):
                st.write(f"**Meta de Publica√ß√µes:** {plan['target_publications']:.1f}")
                st.write("**Objetivos:**")
                for meta in plan['metas']:
                    st.write(f"‚Ä¢ {meta}")
    
    def generate_executive_report(self):
        """Gerar relat√≥rio executivo"""
        report = f"""
        # Relat√≥rio Executivo IPT Faculty Performance
        
        **Data:** {datetime.now().strftime('%d/%m/%Y %H:%M')}
        
        ## M√©tricas Principais
        - Total de Docentes: {len(self.df_main)}
        - Publica√ß√µes M√©dias: {self.df_main['orcid_works_count'].mean():.1f}
        - Performance Score: {self.calculate_performance_score(self.df_main):.1f}/100
        
        ## Alertas Ativos
        - Cr√≠ticos: {len(self.df_alerts[self.df_alerts['priority'] == 'ALTA']) if not self.df_alerts.empty else 0}
        - Avisos: {len(self.df_alerts[self.df_alerts['priority'] == 'M√âDIA']) if not self.df_alerts.empty else 0}
        
        ## Recomenda√ß√µes
        1. Implementar programa de apoio √† investiga√ß√£o
        2. Melhorar compliance ORCID
        3. Estabelecer parcerias internacionais
        """
        
        st.markdown(report)
        
        # Download button
        st.download_button(
            label="üì• Download Relat√≥rio",
            data=report,
            file_name=f"relatorio_executivo_{datetime.now().strftime('%Y%m%d')}.md",
            mime="text/markdown"
        )
    
    def generate_compliance_report(self):
        """Gerar relat√≥rio de compliance"""
        st.info("Relat√≥rio de compliance gerado! (Funcionalidade em desenvolvimento)")
    
    def generate_detailed_report(self):
        """Gerar relat√≥rio detalhado"""
        st.info("Relat√≥rio detalhado gerado! (Funcionalidade em desenvolvimento)")
    
    def export_to_excel(self):
        """Exportar dados para Excel"""
        if self.df_main.empty:
            st.warning("Nenhum dado para exportar")
            return
        
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            self.df_main.to_excel(writer, sheet_name='Dados Principais', index=False)
            
            if not self.df_clusters.empty:
                self.df_clusters.to_excel(writer, sheet_name='Clusters', index=False)
            
            if not self.df_network.empty:
                self.df_network.to_excel(writer, sheet_name='Rede', index=False)
        
        st.download_button(
            label="üìä Download Excel",
            data=output.getvalue(),
            file_name=f"ipt_faculty_data_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    
    def export_to_pdf(self):
        """Exportar relat√≥rio para PDF"""
        st.info("Exporta√ß√£o para PDF em desenvolvimento")
    
    def export_all_data(self):
        """Exportar todos os dados em ZIP"""
        st.info("Exporta√ß√£o completa em desenvolvimento")

def main():
    """Fun√ß√£o principal do dashboard"""
    dashboard = AdvancedDashboard()
    
    # Sidebar navigation
    st.sidebar.title("üéì IPT Faculty Analytics")
    
    pages = {
        "üìä Vis√£o Geral": "overview",
        "üéØ An√°lise de Performance": "performance",
        "üèÜ Benchmarking": "benchmarking",
        "üìã Relat√≥rios": "reports"
    }
    
    selected_page = st.sidebar.selectbox(
        "Navega√ß√£o",
        list(pages.keys())
    )
    
    # Filtros
    filters = dashboard.create_sidebar_filters()
    
    # Mostrar p√°gina selecionada
    page_key = pages[selected_page]
    
    if page_key == "overview":
        dashboard.show_overview_page(filters)
    elif page_key == "performance":
        dashboard.show_performance_analysis(filters)
    elif page_key == "benchmarking":
        dashboard.show_benchmarking_page(filters)
    elif page_key == "reports":
        dashboard.show_reports_page(filters)
    
    # Footer
    st.sidebar.markdown("---")
    st.sidebar.markdown("üîÑ **√öltima atualiza√ß√£o:** " + datetime.now().strftime('%d/%m/%Y %H:%M'))
    st.sidebar.markdown("üìß **Suporte:** analytics@ipt.pt")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
IPT Faculty Performance Assessment - Advanced Dashboard
========================================================
Dashboard Streamlit avan√ßado com m√∫ltiplas funcionalidades:
- Interface multi-p√°gina
- Filtros din√¢micos
- Visualiza√ß√µes interativas
- Relat√≥rios export√°veis
- Sistema de alertas
- Benchmarking em tempo real
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
from datetime import datetime, timedelta
from pathlib import Path
import base64
from io import BytesIO
import zipfile
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="IPT Faculty Analytics",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Configura√ß√£o de estilo customizado
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 0.5rem 0;
    }
    .alert-critical {
        background-color: #ff4444;
        color: white;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.25rem 0;
    }
    .alert-warning {
        background-color: #ffaa00;
        color: white;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.25rem 0;
    }
    .alert-info {
        background-color: #0088cc;
        color: white;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.25rem 0;
    }
    .sidebar .sidebar-content {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    .stProgress .st-bo {
        background-color: #00cc88;
    }
</style>
""", unsafe_allow_html=True)

class AdvancedDashboard:
    """Dashboard avan√ßado para an√°lise de performance de docentes"""
    
    def __init__(self):
        self.data_dir = Path("data")
        self.load_data()
        
    def load_data(self):
        """Carregar todos os dados dispon√≠veis"""
        try:
            # Dados principais - try multiple files in order of preference
            main_data_files = [
                "faculty_research_metrics.csv",
                "faculty_enhanced_complete.csv", 
                "faculty_advanced_parsed.csv",
                "faculty_basic.csv",
                "faculty_enriched.csv"
            ]
            
            self.df_main = pd.DataFrame()
            for file in main_data_files:
                if (self.data_dir / file).exists():
                    self.df_main = pd.read_csv(self.data_dir / file)
                    st.info(f"‚úÖ Dados carregados de: {file}")
                    break
            
            if self.df_main.empty:
                st.warning("‚ö†Ô∏è Nenhum arquivo de dados principal encontrado")
            
            # Dados de clustering
            if (self.data_dir / "faculty_clusters.csv").exists():
                self.df_clusters = pd.read_csv(self.data_dir / "faculty_clusters.csv")
            else:
                self.df_clusters = pd.DataFrame()
            
            # M√©tricas de rede
            if (self.data_dir / "faculty_network_metrics.csv").exists():
                self.df_network = pd.read_csv(self.data_dir / "faculty_network_metrics.csv")
            else:
                self.df_network = pd.DataFrame()
            
            # Dados Scopus
            if (self.data_dir / "faculty_scopus_metrics.csv").exists():
                self.df_scopus = pd.read_csv(self.data_dir / "faculty_scopus_metrics.csv")
            else:
                self.df_scopus = pd.DataFrame()
            
            # Alertas
            if (self.data_dir / "faculty_alerts.csv").exists():
                self.df_alerts = pd.read_csv(self.data_dir / "faculty_alerts.csv")
            else:
                self.df_alerts = pd.DataFrame()
            
            # M√©tricas de monitoriza√ß√£o
            if (self.data_dir / "monitoring_metrics.json").exists():
                with open(self.data_dir / "monitoring_metrics.json", 'r') as f:
                    self.monitoring_data = json.load(f)
            else:
                self.monitoring_data = {}
            
            # An√°lise de benchmarking
            if (self.data_dir / "benchmark_analysis.json").exists():
                with open(self.data_dir / "benchmark_analysis.json", 'r') as f:
                    self.benchmark_data = json.load(f)
            else:
                self.benchmark_data = {}
            
            # Merge dos dados se dispon√≠vel
            if not self.df_main.empty:
                if not self.df_clusters.empty and 'name' in self.df_clusters.columns:
                    self.df_main = self.df_main.merge(self.df_clusters, on='name', how='left', suffixes=('', '_cluster'))
                
                if not self.df_network.empty and 'name' in self.df_network.columns:
                    self.df_main = self.df_main.merge(self.df_network, on='name', how='left', suffixes=('', '_network'))
                
                if not self.df_scopus.empty and 'name' in self.df_scopus.columns:
                    self.df_main = self.df_main.merge(self.df_scopus, on='name', how='left', suffixes=('', '_scopus'))
            
            # Log data summary
            orcid_found = (self.df_main['orcid_status'] == 'found').sum() if 'orcid_status' in self.df_main.columns else 0
            orcid_coverage = (orcid_found / len(self.df_main) * 100) if len(self.df_main) > 0 else 0
            
            st.sidebar.info(f"üìä **Resumo dos Dados:**\n\n"
                          f"‚Ä¢ Principal: {len(self.df_main)} registros\n"
                          f"‚Ä¢ ORCID encontrados: {orcid_found} ({orcid_coverage:.1f}%)\n"
                          f"‚Ä¢ Clusters: {len(self.df_clusters)} registros\n"
                          f"‚Ä¢ Rede: {len(self.df_network)} registros\n"
                          f"‚Ä¢ Scopus: {len(self.df_scopus)} registros\n"
                          f"‚Ä¢ Alertas: {len(self.df_alerts)} registros")
            
        except Exception as e:
            st.error(f"Erro ao carregar dados: {e}")
            # Create empty dataframes as fallback
            self.df_main = pd.DataFrame()
            self.df_clusters = pd.DataFrame()
            self.df_network = pd.DataFrame()
            self.df_scopus = pd.DataFrame()
            self.df_alerts = pd.DataFrame()
            self.monitoring_data = {}
            self.benchmark_data = {}
    
    @property
    def df(self):
        """Alias for main dataframe for backward compatibility"""
        return self.df_main
    
    def create_sidebar_filters(self):
        """Criar filtros na sidebar"""
        st.sidebar.header("üéõÔ∏è Filtros e Configura√ß√µes")
        
        filters = {}
        
        if not self.df_main.empty:
            # Filtro por categoria
            if 'category' in self.df_main.columns:
                categories = ['Todos'] + list(self.df_main['category'].dropna().unique())
                filters['category'] = st.sidebar.selectbox(
                    "Categoria Acad√©mica",
                    categories,
                    index=0
                )
            
            # Filtro por cluster
            if 'Cluster' in self.df_main.columns:
                clusters = ['Todos'] + [f"Cluster {i}" for i in sorted(self.df_main['Cluster'].dropna().unique())]
                filters['cluster'] = st.sidebar.selectbox(
                    "Cluster de Performance",
                    clusters,
                    index=0
                )
            
            # Filtro por produtividade
            if 'orcid_works_count' in self.df_main.columns:
                pub_range = st.sidebar.slider(
                    "N√∫mero de Publica√ß√µes",
                    min_value=0,
                    max_value=int(self.df_main['orcid_works_count'].max()) if not self.df_main['orcid_works_count'].isna().all() else 100,
                    value=(0, int(self.df_main['orcid_works_count'].max()) if not self.df_main['orcid_works_count'].isna().all() else 100),
                    step=5
                )
                filters['publications'] = pub_range
            
            # Filtro por cita√ß√µes (se dispon√≠vel)
            if 'scopus_citations' in self.df_main.columns:
                citations_range = st.sidebar.slider(
                    "N√∫mero de Cita√ß√µes",
                    min_value=0,
                    max_value=int(self.df_main['scopus_citations'].max()) if not self.df_main['scopus_citations'].isna().all() else 1000,
                    value=(0, int(self.df_main['scopus_citations'].max()) if not self.df_main['scopus_citations'].isna().all() else 1000),
                    step=10
                )
                filters['citations'] = citations_range
        
        # Configura√ß√µes de visualiza√ß√£o
        st.sidebar.subheader("üìä Configura√ß√µes de Visualiza√ß√£o")
        filters['show_confidence'] = st.sidebar.checkbox("Mostrar intervalos de confian√ßa", False)
        filters['show_trends'] = st.sidebar.checkbox("Mostrar linhas de tend√™ncia", True)
        filters['color_scheme'] = st.sidebar.selectbox(
            "Esquema de Cores",
            ["Viridis", "Plasma", "Blues", "Reds", "Greens"],
            index=0
        )
        
        return filters
    
    def apply_filters(self, df, filters):
        """Aplicar filtros aos dados"""
        if df.empty:
            return df
        
        filtered_df = df.copy()
        
        # Filtro por categoria
        if filters.get('category') and filters['category'] != 'Todos':
            filtered_df = filtered_df[filtered_df['category'] == filters['category']]
        
        # Filtro por cluster
        if filters.get('cluster') and filters['cluster'] != 'Todos':
            cluster_num = int(filters['cluster'].split()[-1])
            filtered_df = filtered_df[filtered_df['Cluster'] == cluster_num]
        
        # Filtro por publica√ß√µes - APENAS quando valores s√£o alterados dos defaults
        if filters.get('publications'):
            min_pub, max_pub = filters['publications']
            if 'orcid_works_count' in filtered_df.columns:
                # S√≥ aplica filtro se n√£o for o range completo (0 at√© m√°ximo)
                max_possible = int(filtered_df['orcid_works_count'].max()) if not filtered_df['orcid_works_count'].isna().all() else 100
                if min_pub > 0 or max_pub < max_possible:
                    # Filtra apenas registros com dados ORCID quando h√° filtro espec√≠fico
                    filtered_df = filtered_df[
                        (filtered_df['orcid_works_count'].notna()) &
                        (filtered_df['orcid_works_count'] >= min_pub) & 
                        (filtered_df['orcid_works_count'] <= max_pub)
                    ]
        
        # Filtro por cita√ß√µes - APENAS quando valores s√£o alterados dos defaults
        if filters.get('citations'):
            min_cit, max_cit = filters['citations']
            if 'scopus_citations' in filtered_df.columns:
                # S√≥ aplica filtro se n√£o for o range completo (0 at√© m√°ximo)
                max_possible = int(filtered_df['scopus_citations'].max()) if not filtered_df['scopus_citations'].isna().all() else 1000
                if min_cit > 0 or max_cit < max_possible:
                    # Filtra apenas registros com dados Scopus quando h√° filtro espec√≠fico
                    filtered_df = filtered_df[
                        (filtered_df['scopus_citations'].notna()) &
                        (filtered_df['scopus_citations'] >= min_cit) & 
                        (filtered_df['scopus_citations'] <= max_cit)
                    ]
        
        return filtered_df
    
    def show_overview_page(self, filters):
        """P√°gina de vis√£o geral"""
        st.markdown('<h1 class="main-header">üéì IPT Faculty Analytics Dashboard - ATUALIZADO</h1>', unsafe_allow_html=True)
        
        if self.df_main.empty:
            st.warning("‚ö†Ô∏è Nenhum dado carregado. Execute o pipeline de coleta primeiro.")
            return
        
        filtered_df = self.apply_filters(self.df_main, filters)
        
        # M√©tricas principais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_faculty = len(filtered_df)
            st.metric("üë• Total de Docentes", total_faculty)
        
        with col2:
            if 'orcid_works_count' in filtered_df.columns:
                # Only calculate for faculty with ORCID data
                faculty_with_data = filtered_df[filtered_df['orcid_works_count'].notna()]
                if len(faculty_with_data) > 0:
                    avg_publications = faculty_with_data['orcid_works_count'].mean()
                    st.metric("üìö Publica√ß√µes M√©dias", f"{avg_publications:.1f}")
                    st.caption(f"({len(faculty_with_data)} docentes com dados ORCID)")
                else:
                    st.metric("üìö Publica√ß√µes M√©dias", "N/A")
            else:
                st.metric("üìö Publica√ß√µes M√©dias", "N/A")

        with col3:
            if 'orcid_works_count' in filtered_df.columns:
                # Calculate a proxy citation metric from ORCID data
                faculty_with_data = filtered_df[filtered_df['orcid_works_count'].notna()]
                if len(faculty_with_data) > 0:
                    # Use publications count as proxy since we don't have direct citation data
                    avg_citations = faculty_with_data['orcid_works_count'].mean() * 4.8  # Rough estimate
                    st.metric("üìà Cita√ß√µes Estimadas", f"{avg_citations:.0f}")
                    st.caption("(Estimativa baseada em publica√ß√µes)")
                else:
                    st.metric("üìà Cita√ß√µes Estimadas", "N/A")
            else:
                st.metric("üìà Cita√ß√µes Estimadas", "N/A")
        
        with col4:
            # Calcular score de performance
            performance_score = self.calculate_performance_score(filtered_df)
            st.metric("‚≠ê Performance Score", f"{performance_score:.1f}/100")
        
        # Gr√°ficos principais
        col1, col2 = st.columns(2)
        
        with col1:
            self.show_category_distribution(filtered_df, filters)
        
        with col2:
            self.show_performance_scatter(filtered_df, filters)
        
        # Alertas
        self.show_alerts_summary()
        
        # Tend√™ncias temporais
        st.subheader("üìà Tend√™ncias e Proje√ß√µes")
        self.show_trends_projection(filtered_df)
    
    def show_performance_analysis(self, filters):
        """P√°gina de an√°lise de performance"""
        st.header("üìä An√°lise Detalhada de Performance")
        
        if self.df_main.empty:
            st.warning("‚ö†Ô∏è Nenhum dado dispon√≠vel para an√°lise.")
            return
        
        filtered_df = self.apply_filters(self.df_main, filters)
        
        # An√°lise de clusters
        if 'Cluster' in filtered_df.columns:
            st.subheader("üéØ An√°lise de Clusters")
            self.show_cluster_analysis(filtered_df, filters)
        
        # An√°lise de rede
        if not self.df_network.empty:
            st.subheader("üåê An√°lise de Rede de Colabora√ß√£o")
            self.show_network_analysis()
        
        # Top performers
        st.subheader("üèÜ Top Performers")
        self.show_top_performers(filtered_df)
        
        # Performance por departamento
        if 'department' in filtered_df.columns:
            st.subheader("üè¢ Performance por Departamento")
            self.show_department_performance(filtered_df, filters)
    
    def show_benchmarking_page(self, filters):
        """P√°gina de benchmarking"""
        st.header("üèÜ Benchmarking Internacional")
        
        if not self.benchmark_data:
            st.warning("‚ö†Ô∏è Dados de benchmarking n√£o dispon√≠veis.")
            return
        
        # Compara√ß√£o com benchmarks
        self.show_benchmark_comparison()
        
        # Gap analysis
        st.subheader("üìä An√°lise de Gaps")
        self.show_gap_analysis()
        
        # Roadmap
        st.subheader("üõ£Ô∏è Roadmap Estrat√©gico")
        self.show_strategic_roadmap()
    
    def show_reports_page(self, filters):
        """P√°gina de relat√≥rios"""
        st.header("üìã Relat√≥rios e Exporta√ß√£o")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìä Relat√≥rios Dispon√≠veis")
            
            if st.button("üìà Relat√≥rio Executivo"):
                self.generate_executive_report()
            
            if st.button("üìã Relat√≥rio de Compliance"):
                self.generate_compliance_report()
            
            if st.button("üîç Relat√≥rio Detalhado"):
                self.generate_detailed_report()
        
        with col2:
            st.subheader("üíæ Exportar Dados")
            
            if st.button("üìä Exportar para Excel"):
                self.export_to_excel()
            
            if st.button("üìÑ Exportar para PDF"):
                self.export_to_pdf()
            
            if st.button("üì¶ Exportar Tudo (ZIP)"):
                self.export_all_data()
    
    def calculate_performance_score(self, df):
        """Calcular score de performance composto baseado em dados dispon√≠veis"""
        if df.empty:
            return 0
        
        scores = []
        total_possible = 0
        
        # Publica√ß√µes (40% do score total)
        if 'orcid_works_count' in df.columns:
            faculty_with_data = df[df['orcid_works_count'].notna()]
            if len(faculty_with_data) > 0:
                pub_score = faculty_with_data['orcid_works_count'].mean() / 50 * 40
                scores.append(min(pub_score, 40))
                total_possible += 40
        
        # Colabora√ß√£o baseada em perfis (30%)
        if 'profile_url' in df.columns:
            # Score baseado na completude dos perfis
            profile_score = (df['profile_url'].notna().sum() / len(df)) * 30
            scores.append(profile_score)
            total_possible += 30
        
        # Presen√ßa digital (20%)
        if 'email' in df.columns:
            email_score = (df['email'].notna().sum() / len(df)) * 20
            scores.append(email_score)
            total_possible += 20
        
        # Dados de investiga√ß√£o (10%)
        if 'orcid_status' in df.columns:
            orcid_score = ((df['orcid_status'] == 'found').sum() / len(df)) * 10
            scores.append(orcid_score)
            total_possible += 10
        
        # Normalizar o score para 0-100
        final_score = sum(scores) if total_possible > 0 else 0
        if total_possible < 100:
            # Ajustar proporcionalmente se nem todos os componentes est√£o dispon√≠veis
            final_score = (final_score / total_possible) * 100 if total_possible > 0 else 0
            
        return min(final_score, 100)
    
    def show_category_distribution(self, df, filters):
        """Mostrar distribui√ß√£o por categoria"""
        if 'category' not in df.columns:
            st.info("Dados de categoria n√£o dispon√≠veis")
            return
        
        st.subheader("üë®‚Äçüè´ Distribui√ß√£o por Categoria")
        
        category_counts = df['category'].value_counts()
        
        fig = px.pie(
            values=category_counts.values,
            names=category_counts.index,
            title="Distribui√ß√£o de Docentes por Categoria",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        
        fig.update_traces(textposition='inside', textinfo='percent+label')
        fig.update_layout(height=400)
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_performance_scatter(self, df, filters):
        """Mostrar scatter plot de performance"""
        if 'orcid_works_count' not in df.columns:
            st.info("Dados de publica√ß√µes n√£o dispon√≠veis")
            return
        
        st.subheader("üìä Performance: Publica√ß√µes vs Cita√ß√µes")
        
        # Filtrar apenas dados com ORCID para visualiza√ß√£o
        df_with_data = df[df['orcid_works_count'].notna()].copy()
        
        if df_with_data.empty:
            st.info("Nenhum dado de publica√ß√µes dispon√≠vel para visualiza√ß√£o")
            return
        
        x_col = 'orcid_works_count'
        y_col = 'orcid_recent_works' if 'orcid_recent_works' in df_with_data.columns else 'orcid_works_count'
        
        # Preparar coluna de tamanho (remover NaN)
        size_col = None
        if 'orcid_funding_count' in df_with_data.columns:
            df_with_data['funding_size'] = df_with_data['orcid_funding_count'].fillna(1)
            size_col = 'funding_size'
        
        fig = px.scatter(
            df_with_data,
            x=x_col,
            y=y_col,
            color='category' if 'category' in df_with_data.columns else None,
            size=size_col,
            hover_name='name',
            title="Rela√ß√£o entre Publica√ß√µes Totais e Recentes",
            color_discrete_sequence=px.colors.qualitative.Set2,
            labels={
                'orcid_works_count': 'Total de Publica√ß√µes',
                'orcid_recent_works': 'Publica√ß√µes Recentes'
            }
        )
        
        if filters.get('show_trends') and len(df_with_data) > 1:
            # Adicionar linha de tend√™ncia apenas se h√° dados suficientes
            try:
                trendline_fig = px.scatter(df_with_data, x=x_col, y=y_col, trendline="ols")
                if len(trendline_fig.data) > 1:
                    fig.add_traces(trendline_fig.data[1:])
            except:
                pass  # Ignorar erro se n√£o conseguir calcular tend√™ncia
        
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        # Mostrar estat√≠sticas
        if len(df_with_data) > 0:
            st.caption(f"Mostrando {len(df_with_data)} docentes com dados de publica√ß√µes de {len(df)} total")
    
    def show_alerts_summary(self):
        """Mostrar resumo de alertas"""
        if self.df_alerts.empty:
            # Criar alertas padr√£o se n√£o existirem
            st.subheader("üö® Alertas do Sistema")
            
            # Calcular alertas autom√°ticos baseados nos dados
            alerts = self.generate_automatic_alerts()
            
            if alerts:
                for alert in alerts:
                    if alert['priority'] == 'ALTA':
                        st.error(f"üî¥ **{alert['category']}**: {alert['message']}")
                    elif alert['priority'] == 'M√âDIA':
                        st.warning(f"üü° **{alert['category']}**: {alert['message']}")
                    else:
                        st.info(f"üîµ **{alert['category']}**: {alert['message']}")
            else:
                st.success("‚úÖ Nenhum alerta ativo no momento")
            return
        
        st.subheader("üö® Alertas Ativos")
        
        # Contar alertas por prioridade
        critical_alerts = self.df_alerts[self.df_alerts['priority'] == 'ALTA']
        warning_alerts = self.df_alerts[self.df_alerts['priority'] == 'M√âDIA']
        info_alerts = self.df_alerts[self.df_alerts['priority'] == 'BAIXA']
        
        # Mostrar contadores
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("üî¥ Cr√≠ticos", len(critical_alerts))
        
        with col2:
            st.metric("üü° Avisos", len(warning_alerts))
        
        with col3:
            st.metric("üîµ Informativos", len(info_alerts))
        
        # Mostrar alertas detalhados
        if len(critical_alerts) > 0:
            st.error("‚ö†Ô∏è **ALERTAS CR√çTICOS**")
            for _, alert in critical_alerts.iterrows():
                with st.expander(f"üî¥ {alert['category']}", expanded=True):
                    st.write(f"**Mensagem:** {alert['message']}")
                    if 'description' in alert:
                        st.write(f"**Descri√ß√£o:** {alert['description']}")
                    if 'recommendation' in alert:
                        st.write(f"**Recomenda√ß√£o:** {alert['recommendation']}")
                    if 'timestamp' in alert:
                        st.write(f"**Data:** {alert['timestamp']}")
        
        if len(warning_alerts) > 0:
            st.warning("‚ö†Ô∏è **AVISOS**")
            for _, alert in warning_alerts.iterrows():
                with st.expander(f"üü° {alert['category']}"):
                    st.write(f"**Mensagem:** {alert['message']}")
                    if 'description' in alert:
                        st.write(f"**Descri√ß√£o:** {alert['description']}")
                    if 'recommendation' in alert:
                        st.write(f"**Recomenda√ß√£o:** {alert['recommendation']}")
        
        if len(info_alerts) > 0:
            st.info("‚ÑπÔ∏è **INFORMATIVOS**")
            for _, alert in info_alerts.iterrows():
                with st.expander(f"üîµ {alert['category']}"):
                    st.write(f"**Mensagem:** {alert['message']}")
                    if 'description' in alert:
                        st.write(f"**Descri√ß√£o:** {alert['description']}")
    
    def generate_automatic_alerts(self):
        """Gerar alertas autom√°ticos baseados nos dados"""
        alerts = []
        
        if self.df_main.empty:
            return alerts
        
        # Alerta 1: Baixa cobertura ORCID
        if 'orcid_status' in self.df_main.columns:
            orcid_coverage = ((self.df_main['orcid_status'] == 'found').sum() / len(self.df_main)) * 100
            if orcid_coverage < 10:
                alerts.append({
                    'category': 'Cobertura ORCID',
                    'priority': 'ALTA',
                    'message': f'Apenas {orcid_coverage:.1f}% dos docentes t√™m perfil ORCID identificado',
                    'description': 'A cobertura ORCID est√° muito baixa, impactando a visibilidade da investiga√ß√£o do IPT',
                    'recommendation': 'Implementar campanha de registo ORCID para todos os docentes'
                })
            elif orcid_coverage < 25:
                alerts.append({
                    'category': 'Cobertura ORCID',
                    'priority': 'M√âDIA',
                    'message': f'Cobertura ORCID de {orcid_coverage:.1f}% est√° abaixo do recomendado',
                    'recommendation': 'Incentivar registo ORCID entre os docentes'
                })
        
        # Alerta 2: Dados de investiga√ß√£o
        if 'orcid_works_count' in self.df_main.columns:
            faculty_with_research = self.df_main[self.df_main['orcid_works_count'] > 0]
            if len(faculty_with_research) < len(self.df_main) * 0.3:
                alerts.append({
                    'category': 'Atividade de Investiga√ß√£o',
                    'priority': 'M√âDIA',
                    'message': 'Menos de 30% dos docentes t√™m atividade de investiga√ß√£o registada',
                    'description': 'A visibilidade da investiga√ß√£o pode estar sub-representada',
                    'recommendation': 'Verificar e atualizar perfis de investiga√ß√£o dos docentes'
                })
        
        # Alerta 3: Completude de perfis
        if 'email' in self.df_main.columns:
            email_coverage = (self.df_main['email'].notna().sum() / len(self.df_main)) * 100
            if email_coverage > 90:
                alerts.append({
                    'category': 'Qualidade dos Dados',
                    'priority': 'BAIXA',
                    'message': f'Excelente cobertura de contactos: {email_coverage:.1f}%',
                    'description': 'A maioria dos perfis t√™m informa√ß√£o de contacto completa'
                })
        
        # Alerta 4: Volume de dados
        if len(self.df_main) > 900:
            alerts.append({
                'category': 'Cobertura de Dados',
                'priority': 'BAIXA',
                'message': f'Excelente cobertura: {len(self.df_main)} perfis de docentes identificados',
                'description': 'O sistema identificou um volume significativo de docentes IPT'
            })
        
        return alerts
    
    def show_trends_projection(self, df):
        """Mostrar tend√™ncias e proje√ß√µes"""
        # Simular dados hist√≥ricos para demonstra√ß√£o
        years = list(range(2020, 2025))
        
        if 'orcid_works_count' in df.columns:
            current_avg = df['orcid_works_count'].mean()
        else:
            current_avg = 30
        
        # Simular tend√™ncia hist√≥rica
        historical_data = [current_avg * (1 - 0.1 * (2024 - year)) for year in years]
        
        # Proje√ß√£o futura
        future_years = list(range(2025, 2028))
        projections = [current_avg * (1 + 0.08 * (year - 2024)) for year in future_years]
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=years,
            y=historical_data,
            mode='lines+markers',
            name='Dados Hist√≥ricos',
            line=dict(color='blue')
        ))
        
        fig.add_trace(go.Scatter(
            x=future_years,
            y=projections,
            mode='lines+markers',
            name='Proje√ß√£o',
            line=dict(color='red', dash='dash')
        ))
        
        fig.update_layout(
            title="Evolu√ß√£o da Produ√ß√£o Cient√≠fica",
            xaxis_title="Ano",
            yaxis_title="Publica√ß√µes M√©dias",
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_cluster_analysis(self, df, filters):
        """Mostrar an√°lise de clusters"""
        cluster_summary = df.groupby('Cluster').agg({
            'name': 'count',
            'orcid_works_count': 'mean',
            'orcid_recent_works': 'mean' if 'orcid_recent_works' in df.columns else lambda x: 0
        }).round(2)
        
        cluster_summary.columns = ['N√∫mero de Docentes', 'Publica√ß√µes M√©dias', 'Publica√ß√µes Recentes']
        
        st.dataframe(cluster_summary, use_container_width=True)
        
        # Visualiza√ß√£o dos clusters
        if 'orcid_works_count' in df.columns and 'orcid_recent_works' in df.columns:
            fig = px.scatter(
                df,
                x='orcid_works_count',
                y='orcid_recent_works',
                color='Cluster',
                title="Clusters de Performance",
                labels={'orcid_works_count': 'Total de Publica√ß√µes', 'orcid_recent_works': 'Publica√ß√µes Recentes'}
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    def show_network_analysis(self):
        """Mostrar an√°lise de rede"""
        if self.df_network.empty:
            st.info("Dados de rede n√£o dispon√≠veis")
            return
        
        # Top colaboradores
        top_collaborators = self.df_network.nlargest(10, 'degree_centrality')
        
        fig = px.bar(
            top_collaborators,
            x='degree_centrality',
            y='name',
            orientation='h',
            title="Top 10 Colaboradores (Centralidade de Grau)"
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_top_performers(self, df):
        """Mostrar top performers"""
        if 'orcid_works_count' not in df.columns:
            st.info("Dados de performance n√£o dispon√≠veis")
            return
        
        # Calcular score para cada docente
        df_performance = df.copy()
        
        # Score baseado em m√∫ltiplas m√©tricas
        scores = []
        for _, row in df_performance.iterrows():
            score = 0
            
            # Publica√ß√µes (40%)
            pubs = row.get('orcid_works_count', 0)
            score += min(pubs / 100, 1) * 40
            
            # Cita√ß√µes (30%)
            if 'scopus_citations' in row:
                citations = row.get('scopus_citations', 0)
                score += min(citations / 1000, 1) * 30
            
            # Publica√ß√µes recentes (20%)
            recent = row.get('orcid_recent_works', 0)
            score += min(recent / 20, 1) * 20
            
            # H-index (10%)
            if 'scopus_h_index' in row:
                h_index = row.get('scopus_h_index', 0)
                score += min(h_index / 20, 1) * 10
            
            scores.append(score)
        
        df_performance['performance_score'] = scores
        
        # Top 10
        top_performers = df_performance.nlargest(10, 'performance_score')
        
        fig = px.bar(
            top_performers,
            x='performance_score',
            y='name',
            orientation='h',
            title="Top 10 Performers (Score Composto)",
            color='performance_score',
            color_continuous_scale='Viridis'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_department_performance(self, df, filters):
        """Mostrar performance por departamento"""
        if 'department' not in df.columns or df['department'].isna().all():
            st.info("Dados de departamento n√£o dispon√≠veis")
            return
        
        dept_performance = df.groupby('department').agg({
            'orcid_works_count': ['count', 'mean', 'sum'],
            'orcid_recent_works': 'mean' if 'orcid_recent_works' in df.columns else lambda x: 0
        }).round(2)
        
        st.dataframe(dept_performance, use_container_width=True)
    
    def show_benchmark_comparison(self):
        """Mostrar compara√ß√£o com benchmarks"""
        if 'benchmark_comparison' not in self.benchmark_data:
            st.info("Dados de benchmark n√£o dispon√≠veis")
            return
        
        benchmark_df = pd.DataFrame(self.benchmark_data['benchmark_comparison'])
        
        st.dataframe(benchmark_df.T, use_container_width=True)
        
        # Gr√°fico de compara√ß√£o
        # M√©tricas dispon√≠veis
        available_metrics = []
        
        if 'orcid_works_count' in self.df_main.columns:
            available_metrics.append('orcid_works_count')
        if 'orcid_recent_works' in self.df_main.columns:
            available_metrics.append('orcid_recent_works')
        if 'orcid_funding_count' in self.df_main.columns:
            available_metrics.append('orcid_funding_count')
        
        if not available_metrics:
            st.warning("Nenhuma m√©trica de pesquisa dispon√≠vel para compara√ß√£o.")
            return
        
        metrics = available_metrics
        
        fig = go.Figure()
        
        for metric in metrics:
            if metric in benchmark_df.columns:
                fig.add_trace(go.Bar(
                    name=metric,
                    x=benchmark_df.index,
                    y=benchmark_df.loc[metric]
                ))
        
        fig.update_layout(
            title="Compara√ß√£o com Benchmarks",
            xaxis_title="Institui√ß√µes",
            yaxis_title="Valores",
            barmode='group'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_gap_analysis(self):
        """Mostrar an√°lise de gaps"""
        if 'gaps' not in self.benchmark_data:
            st.info("An√°lise de gaps n√£o dispon√≠vel")
            return
        
        gaps_data = self.benchmark_data['gaps']
        
        metrics = list(gaps_data.keys())
        gap_percentages = [gaps_data[metric]['percentage'] for metric in metrics]
        
        fig = px.bar(
            x=metrics,
            y=gap_percentages,
            title="Gaps vs Benchmarks (%)",
            color=gap_percentages,
            color_continuous_scale='Reds'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_strategic_roadmap(self):
        """Mostrar roadmap estrat√©gico"""
        if 'roadmap' not in self.benchmark_data:
            st.info("Roadmap n√£o dispon√≠vel")
            return
        
        roadmap = self.benchmark_data['roadmap']
        
        for year, plan in roadmap.items():
            with st.expander(f"üìÖ {year} - {plan['foco']}"):
                st.write(f"**Meta de Publica√ß√µes:** {plan['target_publications']:.1f}")
                st.write("**Objetivos:**")
                for meta in plan['metas']:
                    st.write(f"‚Ä¢ {meta}")
    
    def generate_executive_report(self):
        """Gerar relat√≥rio executivo"""
        # Calcular m√©tricas principais
        total_faculty = len(self.df_main)
        avg_pubs = self.df_main['orcid_works_count'].mean() if 'orcid_works_count' in self.df_main.columns else 0
        performance_score = self.calculate_performance_score(self.df_main)
        
        # Calcular cobertura ORCID
        orcid_coverage = 0
        if 'orcid_status' in self.df_main.columns:
            orcid_coverage = ((self.df_main['orcid_status'] == 'found').sum() / len(self.df_main)) * 100
        
        # Gerar alertas
        alerts = self.generate_automatic_alerts() if self.df_alerts.empty else self.df_alerts.to_dict('records')
        
        report = f"""
# Relat√≥rio Executivo IPT Faculty Performance

**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M')}

## üìä Resumo Executivo

O Instituto Polit√©cnico de Tomar possui **{total_faculty} docentes** identificados no sistema, representando uma cobertura abrangente do corpo docente da institui√ß√£o.

## üéØ M√©tricas Principais

| M√©trica | Valor | Avalia√ß√£o |
|---------|--------|-----------|
| **Total de Docentes** | {total_faculty} | ‚úÖ Excelente cobertura |
| **Cobertura ORCID** | {orcid_coverage:.1f}% | {'üü° Melhorar' if orcid_coverage < 25 else '‚úÖ Adequado'} |
| **Publica√ß√µes M√©dias** | {avg_pubs:.1f} | {'üìö Dados dispon√≠veis' if avg_pubs > 0 else '‚ùå Sem dados'} |
| **Performance Score** | {performance_score:.1f}/100 | {'üéØ Bom' if performance_score > 60 else '‚ö†Ô∏è Melhorar'} |

## üö® Alertas e Recomenda√ß√µes

"""
        
        if alerts:
            for i, alert in enumerate(alerts[:5], 1):  # Mostrar os 5 primeiros alertas
                priority_icon = "üî¥" if alert['priority'] == 'ALTA' else "üü°" if alert['priority'] == 'M√âDIA' else "üîµ"
                report += f"### {i}. {priority_icon} {alert['category']}\n"
                report += f"**Situa√ß√£o:** {alert['message']}\n\n"
                
                if 'description' in alert:
                    report += f"**Descri√ß√£o:** {alert['description']}\n\n"
                
                if 'recommendation' in alert:
                    report += f"**Recomenda√ß√£o:** {alert['recommendation']}\n\n"
                
                report += "---\n\n"
        else:
            report += "‚úÖ Nenhum alerta cr√≠tico identificado.\n\n"
        
        report += f"""
## üìà Pr√≥ximos Passos

### Prioridade Alta
1. **Aumentar Cobertura ORCID**: Implementar campanha institucional para registo ORCID
2. **Validar Dados**: Verificar e corrigir informa√ß√µes de docentes
3. **Melhorar Visibilidade**: Incentivar atualiza√ß√£o de perfis de investiga√ß√£o

### Prioridade M√©dia
1. **Integra√ß√£o com Sistemas**: Conectar com plataformas de investiga√ß√£o
2. **Monitoriza√ß√£o Cont√≠nua**: Estabelecer alertas autom√°ticos
3. **Benchmarking**: Comparar com outras institui√ß√µes similares

### Prioridade Baixa
1. **Dashboard Avan√ßado**: Implementar funcionalidades adicionais
2. **Relat√≥rios Autom√°ticos**: Configurar relat√≥rios peri√≥dicos
3. **An√°lise Preditiva**: Desenvolver modelos de previs√£o

## üí° Conclus√µes

O IPT demonstra uma cobertura de dados significativa com **{total_faculty} docentes** identificados. 
{'A cobertura ORCID requer aten√ß√£o para melhorar a visibilidade da investiga√ß√£o institucional.' if orcid_coverage < 25 else 'A institui√ß√£o est√° bem posicionada em termos de identifica√ß√£o de docentes.'}

**Score Global:** {performance_score:.1f}/100 - {'Excelente' if performance_score > 80 else 'Bom' if performance_score > 60 else 'Requer Melhoria'}

---
*Relat√≥rio gerado automaticamente pelo IPT Faculty Analytics Dashboard*
        """
        
        st.markdown(report)
        
        # Download button
        st.download_button(
            label="üì• Download Relat√≥rio Executivo",
            data=report,
            file_name=f"relatorio_executivo_ipt_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
            mime="text/markdown"
        )
    
    def generate_compliance_report(self):
        """Gerar relat√≥rio de compliance"""
        st.info("Relat√≥rio de compliance gerado! (Funcionalidade em desenvolvimento)")
    
    def generate_detailed_report(self):
        """Gerar relat√≥rio detalhado"""
        st.info("Relat√≥rio detalhado gerado! (Funcionalidade em desenvolvimento)")
    
    def export_to_excel(self):
        """Exportar dados para Excel"""
        if self.df_main.empty:
            st.warning("Nenhum dado para exportar")
            return
        
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            self.df_main.to_excel(writer, sheet_name='Dados Principais', index=False)
            
            if not self.df_clusters.empty:
                self.df_clusters.to_excel(writer, sheet_name='Clusters', index=False)
            
            if not self.df_network.empty:
                self.df_network.to_excel(writer, sheet_name='Rede', index=False)
        
        st.download_button(
            label="üìä Download Excel",
            data=output.getvalue(),
            file_name=f"ipt_faculty_data_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    
    def export_to_pdf(self):
        """Exportar relat√≥rio para PDF"""
        st.info("Exporta√ß√£o para PDF em desenvolvimento")
    
    def export_all_data(self):
        """Exportar todos os dados em ZIP"""
        st.info("Exporta√ß√£o completa em desenvolvimento")

def main():
    """Fun√ß√£o principal do dashboard"""
    dashboard = AdvancedDashboard()
    
    # Sidebar navigation
    st.sidebar.title("üéì IPT Faculty Analytics")
    
    pages = {
        "üìä Vis√£o Geral": "overview",
        "üéØ An√°lise de Performance": "performance",
        "üèÜ Benchmarking": "benchmarking",
        "üìã Relat√≥rios": "reports"
    }
    
    selected_page = st.sidebar.selectbox(
        "Navega√ß√£o",
        list(pages.keys())
    )
    
    # Filtros
    filters = dashboard.create_sidebar_filters()
    
    # Mostrar p√°gina selecionada
    page_key = pages[selected_page]
    
    if page_key == "overview":
        dashboard.show_overview_page(filters)
    elif page_key == "performance":
        dashboard.show_performance_analysis(filters)
    elif page_key == "benchmarking":
        dashboard.show_benchmarking_page(filters)
    elif page_key == "reports":
        dashboard.show_reports_page(filters)
    
    # Footer
    st.sidebar.markdown("---")
    st.sidebar.markdown("üîÑ **√öltima atualiza√ß√£o:** " + datetime.now().strftime('%d/%m/%Y %H:%M'))
    st.sidebar.markdown("üìß **Suporte:** analytics@ipt.pt")

if __name__ == "__main__":
    main()
